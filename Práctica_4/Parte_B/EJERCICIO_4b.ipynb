{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee71e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0116 GPD\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Inicializa OCR en inglés (alfanumérico)\n",
    "ocr = PaddleOCR(lang='en', use_textline_orientation=True)\n",
    "\n",
    "# Ruta de la imagen\n",
    "path_im = r\"C:\\Users\\javie\\Documents\\TRABAJO UNI\\VC\\Vision_por_Computador\\Práctica_4\\Parte_A\\TGC_RBNW\\train\\images\\0116GPD.jpg\"\n",
    "\n",
    "# Detecta y reconoce texto en la imagen completa\n",
    "ocr_result = ocr.predict(path_im)\n",
    "\n",
    "first_result = ocr_result[0]  # esto es un diccionario\n",
    "\n",
    "# acceder directamente al texto\n",
    "if 'rec_texts' in first_result and len(first_result['rec_texts']) > 0:\n",
    "    texto_matricula = first_result['rec_texts'][0]\n",
    "    print(texto_matricula)\n",
    "else:\n",
    "    texto_matricula = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\javie\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando video (2832 fotogramas)...\n",
      "\n",
      "Procesados 10/2832 fotogramas...\n",
      "Procesados 20/2832 fotogramas...\n",
      "Procesados 30/2832 fotogramas...\n",
      "Procesados 40/2832 fotogramas...\n",
      "Procesados 50/2832 fotogramas...\n",
      "Procesados 60/2832 fotogramas...\n",
      "Procesados 70/2832 fotogramas...\n",
      "Procesados 80/2832 fotogramas...\n",
      "Procesados 90/2832 fotogramas...\n",
      "Procesados 100/2832 fotogramas...\n",
      "Procesados 110/2832 fotogramas...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m start_ocr \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     98\u001b[0m plate_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(plate_crop, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 99\u001b[0m ocr_result \u001b[38;5;241m=\u001b[39m \u001b[43mocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplate_rgb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m tiempo_ocr \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_ocr\n\u001b[0;32m    101\u001b[0m total_tiempo_ocr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tiempo_ocr\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddleocr\\_pipelines\\ocr.py:213\u001b[0m, in \u001b[0;36mPaddleOCR.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, return_word_box)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m     return_word_box\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    212\u001b[0m ):\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_textline_orientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_textline_orientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_word_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_word_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[1;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\pipelines\\ocr\\pipeline.py:343\u001b[0m, in \u001b[0;36m_OCRPipeline.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_max_side_limit, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, return_word_box)\u001b[0m\n\u001b[0;32m    340\u001b[0m image_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_reader(batch_data\u001b[38;5;241m.\u001b[39minstances)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_doc_preprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 343\u001b[0m     doc_preprocessor_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_preprocessor_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_arrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     doc_preprocessor_results \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: arr} \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m image_arrays]\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[1;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\pipelines\\doc_preprocessor\\pipeline.py:175\u001b[0m, in \u001b[0;36m_DocPreprocessorPipeline.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping)\u001b[0m\n\u001b[0;32m    172\u001b[0m     rot_imgs \u001b[38;5;241m=\u001b[39m image_arrays\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_doc_unwarping\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 175\u001b[0m     output_imgs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    176\u001b[0m         item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoctr_img\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_unwarping_model(rot_imgs)\n\u001b[0;32m    178\u001b[0m     ]\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     output_imgs \u001b[38;5;241m=\u001b[39m rot_imgs\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\pipelines\\doc_preprocessor\\pipeline.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m     rot_imgs \u001b[38;5;241m=\u001b[39m image_arrays\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_doc_unwarping\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 175\u001b[0m     output_imgs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    176\u001b[0m         item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoctr_img\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_unwarping_model(rot_imgs)\n\u001b[0;32m    178\u001b[0m     ]\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     output_imgs \u001b[38;5;241m=\u001b[39m rot_imgs\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:273\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, input, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _apply(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.apply\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m     batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m--> 330\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(batch_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m PredictionWrap(prediction, \u001b[38;5;28mlen\u001b[39m(batch_data))\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_data)):\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\image_unwarping\\predictor.py:90\u001b[0m, in \u001b[0;36mWarpPredictor.process\u001b[1;34m(self, batch_data)\u001b[0m\n\u001b[0;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m](imgs\u001b[38;5;241m=\u001b[39mbatch_imgs)\n\u001b[0;32m     89\u001b[0m batch_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(x\u001b[38;5;241m=\u001b[39mx)\n\u001b[1;32m---> 90\u001b[0m batch_warp_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocessors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDocTrPostProcess\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_data\u001b[38;5;241m.\u001b[39minput_paths,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_data\u001b[38;5;241m.\u001b[39mpage_indexes,\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_raw_imgs,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoctr_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_warp_preds,\n\u001b[0;32m     97\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\image_unwarping\\processors.py:64\u001b[0m, in \u001b[0;36mDocTrPostProcess.__call__\u001b[1;34m(self, imgs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m, imgs: List[Union[np\u001b[38;5;241m.\u001b[39mndarray, Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]\n\u001b[0;32m     53\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    Processes a list of images using the `doctr` method.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m        List[np.ndarray]: A list of processed images.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoctr(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\image_unwarping\\processors.py:64\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m, imgs: List[Union[np\u001b[38;5;241m.\u001b[39mndarray, Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]\n\u001b[0;32m     53\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    Processes a list of images using the `doctr` method.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m        List[np.ndarray]: A list of processed images.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoctr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n",
      "File \u001b[1;32mc:\\Users\\javie\\anaconda3\\envs\\VC_P4_paddleOCR\\lib\\site-packages\\paddlex\\inference\\models\\image_unwarping\\processors.py:88\u001b[0m, in \u001b[0;36mDocTrPostProcess.doctr\u001b[1;34m(self, pred)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m     85\u001b[0m     im, np\u001b[38;5;241m.\u001b[39mndarray\n\u001b[0;32m     86\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in DocTrPostProcess. Expected a numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m---> 88\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m im \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m     90\u001b[0m im \u001b[38;5;241m=\u001b[39m im[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "\n",
    "ocr = PaddleOCR(lang='en', use_textline_orientation=True)\n",
    "\n",
    "model_general = YOLO('yolo11n.pt')\n",
    "model_plate = YOLO(\n",
    "    r\"runs\\detect\\matricula_yolo11n\\weights\\best.pt\"\n",
    ")\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "video_path = r\"C0142.MP4\"\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "output_video_path = r\"resultados_video\\\\resultados_deteccion.mp4\"\n",
    "output_csv_path = r\"resultados_video\\\\detecciones_matriculas.csv\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Procesando video ({frame_count} fotogramas)...\\n\")\n",
    "\n",
    "total_tiempo_yolo = 0\n",
    "total_tiempo_ocr = 0\n",
    "num_placas = 0\n",
    "\n",
    "with open(output_csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\n",
    "        \"frame\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "        \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "        \"conf_matricula\",\n",
    "        \"mx1\", \"my1\", \"mx2\", \"my2\", \"texto_matricula\",\n",
    "        \"tiempo_yolo_s\", \"tiempo_ocr_s\"\n",
    "    ])\n",
    "\n",
    "    conteo = Counter()\n",
    "    frame_num = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_num += 1\n",
    "\n",
    "        start_yolo = time.time()\n",
    "        results_general = model_general.track(frame, persist=True, classes=[0, 2],  verbose=False)\n",
    "        tiempo_yolo = time.time() - start_yolo\n",
    "        total_tiempo_yolo += tiempo_yolo\n",
    "\n",
    "        if results_general and len(results_general[0].boxes) > 0:\n",
    "            for box in results_general[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                cls = int(box.cls[0])\n",
    "                label = classNames[cls]\n",
    "                track_id = int(box.id[0]) if box.id is not None else -1\n",
    "\n",
    "                color = (0, 255, 0) if label == \"person\" else (255, 0, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{label} {conf:.2f} ID:{track_id}\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "                conteo[label] += 1\n",
    "                conf_matricula = \"\"\n",
    "                mx1 = my1 = mx2 = my2 = \"\"\n",
    "                texto_matricula = \"\"\n",
    "                tiempo_ocr = 0\n",
    "\n",
    "                if label == \"car\":\n",
    "                    car_crop = frame[y1:y2, x1:x2]\n",
    "                    if car_crop.size > 0:\n",
    "                        results_plate = model_plate.predict(source=car_crop, device=0, verbose=False)\n",
    "                        for p in results_plate:\n",
    "                            for b in p.boxes:\n",
    "                                px1, py1, px2, py2 = map(int, b.xyxy[0])\n",
    "                                pconf = float(b.conf[0])\n",
    "                                mx1, my1, mx2, my2 = x1 + px1, y1 + py1, x1 + px2, y1 + py2\n",
    "                                conf_matricula = round(pconf, 2)\n",
    "                                plate_crop = car_crop[py1:py2, px1:px2]\n",
    "                                if plate_crop.size > 0:\n",
    "                                   \n",
    "\n",
    "                                    start_ocr = time.time()\n",
    "                                    plate_rgb = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2RGB)\n",
    "                                    ocr_result = ocr.predict([plate_rgb])\n",
    "                                    tiempo_ocr = time.time() - start_ocr\n",
    "                                    total_tiempo_ocr += tiempo_ocr\n",
    "                                    num_placas += 1\n",
    "\n",
    "\n",
    "                                    if ocr_result and len(ocr_result[0]) > 0:\n",
    "                                        first_result = ocr_result[0]  # esto es un diccionario\n",
    "\n",
    "                                        # acceder directamente al texto\n",
    "                                        if 'rec_texts' in first_result and len(first_result['rec_texts']) > 0:\n",
    "                                            texto_matricula = first_result['rec_texts'][0]\n",
    "                                        else:\n",
    "                                            texto_matricula = \"\"\n",
    "                                        if texto_matricula:\n",
    "                                            cv2.putText(frame, texto_matricula, (mx1, my2 + 20),\n",
    "                                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "                                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (0, 255, 255), 2)\n",
    "                                cv2.putText(frame, f\"plate {pconf:.2f}\", (mx1, my1 - 5),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                                break\n",
    "\n",
    "                writer.writerow([\n",
    "                    frame_num, label, round(conf, 2), track_id,\n",
    "                    x1, y1, x2, y2,\n",
    "                    conf_matricula,\n",
    "                    mx1, my1, mx2, my2, texto_matricula,\n",
    "                    round(tiempo_yolo, 4), round(tiempo_ocr, 4)\n",
    "                ])\n",
    "\n",
    "        out.write(frame)\n",
    "        if frame_num % 10 == 0:\n",
    "            print(f\"Procesados {frame_num}/{frame_count} fotogramas...\")\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nPROCESAMIENTO COMPLETADO\")\n",
    "print(f\"Video guardado en: {output_video_path}\")\n",
    "print(f\"CSV guardado en: {output_csv_path}\")\n",
    "print(f\"Conteo total: {dict(conteo)}\")\n",
    "if frame_count > 0:\n",
    "    print(f\"Tiempo medio YOLO por frame: {total_tiempo_yolo/frame_count:.4f} s\")\n",
    "if num_placas > 0:\n",
    "    print(f\"Tiempo medio OCR por matrícula: {total_tiempo_ocr/num_placas:.4f} s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4_paddleOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
